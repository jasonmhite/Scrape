#!/usr/bin/python
import feedparser
import urllib2
import ConfigParser
import string
import os

defaults = {"zeropaddedq" : "true"}

def build_searchtable(configfile):
    table = []
    try:
        config = ConfigParser.SafeConfigParser(defaults)
        config.read(configfile)
    except:
	raise NameError('Config Parse Error')

    for sect in config.sections():
        searchstring = config.get(sect, 'sstring')
        episode = config.get(sect, 'currentepisode')
	url = config.get(sect, 'feedurl')
	feed = feedparser.parse(url)
        zeropaddedepnum = config.get(sect, "zeropaddedq")
        if zeropaddedepnum == 'true' and int(episode) < 10:
            episode = "0" + episode
        query = searchstring.replace("*EP", episode)
        table.append((sect,query,feed))
    return(table)

def scan_query(nib):
    res = False
    for entry in nib[2].entries:
        title = filter(lambda x: x in string.printable, entry.title)
        if nib[1] in title:
            res = (nib[0], nib[1], entry.link)
	    return(res)
    return(res)

def scan_searchtable(searchtable):
    hits = []
    for entry in searchtable:
        hit = scan_query(entry)
	if hit:
	    hits.append(hit)
    return(hits)

def update(matchlist, configfile):
    try:
        newconfig = ConfigParser.SafeConfigParser()
        newconfig.read(configfile)
   
        for m in matchlist:
            i = int(newconfig.get(m[0], "currentepisode")) + 1
            newconfig.set(m[0], "currentepisode", str(i))
        with open(configfile, "wb") as updated:
            newconfig.write(updated)
    except:
	raise NameError('Config Replace Error')
def download(matches):
    for entry in matches:
        try:
            dl = urllib2.urlopen(entry[ 2 ], timeout=2)
            with open("/Users/jmhite/Automatically Downloaded/" + entry[1] + '.torrent', 'w') as outfile:
                outfile.write(dl.read())
        except:
	    raise NameError('Download Error')

	#os.system("/usr/local/bin/growlnotify -s -t Scrape -i torrent -m 'Downloading " + str(entry[1]) + "'" )

tab = build_searchtable("list.cfg")
result = scan_searchtable(tab)

update(result, "list.cfg")


